[FOLLOWUP] tag means I need to follow up on what happened.

IDEAS FOR INTEGRATION
 - Custom Menu Options
   - Refresh PBS Placement Sets / Network_Entities
     - need to perform a diff N-1 and N queries - reduce the amount of chatter with PBS when updating the changes

   - Refresh PBS AOEs / Logical_Groups
     - need to perform a diff N-1 and N queries - reduce the amount of chatter with PBS when updating the changes

   - DONE Enable | Disable OS Provisioning
     - Perhaps NOT ALL nodes are eligible to be provisioned. By default nodes are disabled.
       - DONE qmgr -c "s n nodename provision_enable=true"
       - DONE qmgr -c "s n nodename provision_enable=false"

   - DONE Offline Nodes
     - Admin wants to perform maintenance on a node, but would like to allow the work to finish on the node.
       - Offline node
       - Add a comment to the node's attribute, visual cue as to why the node is offline.
         - Consider NOT clobbering previous comments...
       - Assign the node to a special 'nodes_offline' queue.
         - This will ensure that if the node marked online for admin testing, the node will not accept work from the users
         - 'nodes_offline' queue is ACL for 'admins'
       - pbsnodes -o nodename ; qmgr -c "s n nodename comment='Offline/Drain Node for Maintenance'" ; qmgr -c "s n queue=nodes_offline"
     - Consider creating creating a custom HP CMU User Group to bucket the 'nodes_offline'
       - cmu_add_user_group nodes_offline
       - cmu_add_to_user_group -t nodes_offline -f node_file

   - DONE Online Nodes (Production)
     - Admin has 'fixed' the issues and would like to put the node back into production
       - qmgr -c "u n nodename comment" ; qmgr -c "u n nodename queue" ; pbsnodes -c nodename
       - cmu_del_from_user_group -t node_offline -f node_file

   - Online Nodes (Test & Maintenance)
     - After the node has been drained, the admin would like to perform test or maintenance on the offlined node which is now part of a special queue for administrators (nodes_offline)
       - pbsnodes -c nodename

   - DONE Add | Remove node(s) to | from PBS
     - Admin adding nodes to the PBS pool of resources, assuming PBS is part of the image
       - qmgr -c "c n nodename"
     - Admin removing nodes from the PBS pool of resources, perhaps the system is no longer in service.
       - qmgr -c "d n nodename"

 - Detecting Node Warnings, Errors, or Failures
   - Instead of the Admin manually executing an offline or drain node call, this will automatically detect whether a node has a faulty and offline the node
   - Detecting an warning, error, or failure on node(s):
     - Offline node
     - Add a comment to the node's attribute, visual cue as to why the node is offline.
       - Consider NOT clobbering previous comments...
     - Assign the node to a special 'faulty_nodes' queue.
       - This will ensure that if the node marked online for admin testing, the node will not accept work from the users
       - 'faulty_nodes' queue is ACL for 'admins'
     - pbsnodes -o nodename ; qmgr -c "s n nodename comment='Failure Detected: <testnames>'" ; qmgr -c "s n queue=faulty_nodes"
     - Consider creating creating a custom HP CMU User Group to bucket the 'node failures'
       - cmu_add_user_group faulty_nodes
       - cmu_add_to_user_group -t faulty_nodes -f node_file

   - Online Faulty Nodes
     - After the admin has resolved the warnings, errors, or failures, then s/he will want to put the node back into production.
     - If using custom HP CMU User Group to bucket the 'node maintenance' or 'node failures', we need to remove them
       - consider testing for which user_group the node is in, and remove it.. or brute force remove from both?
       - cmu_del_from_user_group -t faulty_nodes -f node_file

   - WIP Detecting Down Nodes
     - If nodes are down (i.e., systems shutdown or PBS Server failed to communicate w/ PBS MOM) send email to 'root'
       - DONE Alert
       - DONE Alert_Reactions
     - Consider creating creating a custom HP CMU User Group to bucket the 'nodes_down'
       - cmu_add_user_group nodes_down
       - cmu_add_to_user_group -t nodes_down -f node_file

   - WIP Detecting Offline Nodes
     - If nodes are offline send email to 'root'
       - DONE Alert
       - DONE Alert_Reactions
     - Consider creating creating a custom HP CMU User Group to bucket the 'nodes_down'
       - cmu_add_user_group nodes_down
       - cmu_add_to_user_group -t nodes_down -f node_file

 - OS Provisioning
   - Update CMU Provisioning Script to take advantage of concurrent node provisioning
     - qmgr -c "create hook provision_hook event = provision"
     - qmgr -c "import hook provision_hook application/x-python default /opt/cmu/contrib/hpcm_pbspro_connector/bin/cmu_os_provision_hook.py"
     - qmgr -c "print hook @default"
        #
        # Create hooks and set their properties.
        #
        #
        # Create and define hook provision_hook
        #
        create hook provision_hook
        set hook provision_hook type = site
        set hook provision_hook enabled = true
        set hook provision_hook event = provision
        set hook provision_hook user = pbsadmin
        set hook provision_hook alarm = 30
        set hook provision_hook order = 1
        import hook provision_hook application/x-python base64 -
        IyBDb3B5cmlnaHQgMjAxMiBBbHRhaXIgRW5naW5lZXJpbmcsIEluYy4gIEFsbCByaWdodHMgcmVzZXJ2ZWQuCiMgVGhpcyBjb2RlIGlzIHByb3ZpZGVkICJhcy1pcyIgd2l0aG91dCBhbnkgd2FycmFudHksIGV4cHJlc3Mgb3IgaW1wbGllZCwgb3IKIyBpbmRlbW5pZmljYXRpb24gb2YgYW55IGtpbmQuICBBbGwgb3RoZXIgdGVybXMgYW5kIGNvbmRpdGlvbnMgYXJlIGFzCiMgc3BlY2lmaWVkIGluIHRoZSBBbHRhaXIgUEJTIEVVTEEuCgppbXBvcnQgcGJzCmltcG9ydCBvcwoKZSA9IHBicy5ldmVudCgpCnZub2RlID0gZS52bm9kZQphb2UgPSBlLmFvZQoKcmV0ID0gb3Muc3lzdGVtKCIvb3B0L2NtdS9jb250cmliL2NtdV9wYnNwcm9fY29ubmVjdG9yL2Jpbi9jbXVfcHJvdmlzaW9uLnNoICIgKyBhb2UgKyAiICIgKyB2bm9kZSk7CmlmIHJldCAhPSAwOgogICBlLnJlamVjdCgiUmVib290IHByb3Zpc2lvbmluZyBmYWlsZWQiLHJldCkKZWxzZToKICAgZS5hY2NlcHQoMCkK
   - Consider the following
     - Installing provision_hook automatically.
     - qsub hook to validate available 'aoe' or 'logical_group'


 - Green Provisioning
   - Power off nodes when workload demand is low
   - Power on nodes when workload demand is high

Updating Mellanox IB Switches, which is using Custom User Group. Therefore, we will key off of IB_switch



NOTES
Lessons learned creating the scripts from scratch.
NOTE: For debugging purposes, consider using cmucli to execute all of the commands and not the CLI interface.

Prerequisites
 - User Account Configured (LDAP, NIS, passwd)
 - Central File System vs Distribute File System
   - User HOME? This will require setup of passwordless SSH/RSH to copy files around in batch mode.
   - Job Execution Directory?
 - Passwordless SSH/SCP or RSH/RCP
   - if SSH/SCP, need to modify /etc/pbs.conf to include PBS_SCP=/usr/bin/scp
   - MPI/Applications Requirement?
   - File Transfers (cp vs distributed(scp/rcp))

Installing PBS Professional on the CMU head node
 - Create the pbsdata account.
   adduser -m pbsdata
 - Do not start services
 - Modify /etc/pbs.conf
   PBS_START_MOM=0
 - Start PBS

Installing PBS Professional on the compute node
 - Installed PBS Pro, Execution Only
 - Installed /etc/profile.d/pbs.[csh|sh]

Creating an image from compute node (Example Below)
 - cmu_add_logical_group -n rhel52_pbs
   - Creates the new logical group; name is based on OS version and PBS installed
 - cmu_add_to_logical_group_candidates -t rhel52_pbs n5
   - Adds the node (n5) to the newly created logical group
 - cmu_show_logical_groups rhel52_pbs
   - Confirms that n5 is in the newly created logical group
   - NOTE: make sure that a network_entity is associated to the logical groups, otherwise you will NOT be able to clone the machine(s)
 - cmu_backup -l rhel52_pbs -n n5 -p "cciss/c0d0p3,cciss/c0d0p1" -e /tmp/n5_back.log
   - Creates backup from n5 to the logical group. -p specifies the partitions (order matters: root first, than others)

[root@serisk1 bin]# ./cmu_backup -l rhel52_pbs -n n5 -p "cciss/c0d0p3,cciss/c0d0p1" -e /tmp/n5_back.log
backup id is 30430
log file is /opt/cmu/log/cmudolly-30430.log
copying ssh settings
hostname setup ok
logout ok
netbooting node
waiting for node n5 to boot
tail -f /opt/cmu/log/cmudolly-30430.log
Starting retrieving fstab
[14-Mar-2012_15:36:34] [Dolly] Running OS : "Linux-RedHat"
[14-Mar-2012_15:36:34] OSTYPE:Linux-CMU
[14-Mar-2012_15:36:34] [DollyClient] Starting to get fstab
[14-Mar-2012_15:36:34] [DollyClient] Getting "/opt/cmu/image/rhel52_pbs/fstab-device.txt"
starting backup process...
[14-Mar-2012_15:36:55] Dolly Terminated...
[14-Mar-2012_15:36:55] [Dolly] Add partition "cciss/c0d0p3"
[14-Mar-2012_15:36:55] [Dolly] Add partition "cciss/c0d0p1"
[14-Mar-2012_15:36:55] [Dolly] Running OS : "Linux-RedHat"
[14-Mar-2012_15:36:55] OSTYPE:Linux-CMU
[14-Mar-2012_15:36:56] [DollyClient]  This is not SLES9 or above. No specific work to do
[14-Mar-2012_15:36:56] [DollyClient]  This is a redhat like OS, launching the script to detect the nic configuration file name used for the cloning
[14-Mar-2012_15:36:56] [DollyClient] Starting to get image
[14-Mar-2012_15:36:56] [DollyClient] Asking for main devices list
[14-Mar-2012_15:36:56] [DollyClient] Device is cciss/c0d0
[14-Mar-2012_15:36:56] [DollyClient] Writing generic reconfiguration file "/opt/cmu/image/rhel52_pbs/reconf.sh" (info...currently-->No such file or directory<--)
[14-Mar-2012_15:36:56] [CMUTools          ]  about to run: -->cp -vf /opt/cmu/etc/reconf.sh /opt/cmu/image/rhel52_pbs/reconf.sh  &> /opt/cmu/tmp/CMU_TEMPO_FILE_qlNDS4<--  cmu_system_helper
[14-Mar-2012_15:36:56] [DollyClient] Writing generic reconfiguration file "/opt/cmu/image/rhel52_pbs/pre_reconf.sh" (info...currently-->No such file or directory<--)
[14-Mar-2012_15:36:56] [CMUTools          ]  about to run: -->cp -vf /opt/cmu/etc/pre_reconf.sh /opt/cmu/image/rhel52_pbs/pre_reconf.sh  &> /opt/cmu/tmp/CMU_TEMPO_FILE_jayqTd<--  cmu_system_helper
[14-Mar-2012_15:36:56] [DollyClient] Asking for partition table of "/dev/cciss/c0d0"
[14-Mar-2012_15:36:56] [DollyClient] Getting /opt/cmu/image/rhel52_pbs/parttbl-c0d0.txt
[14-Mar-2012_15:36:56] [DollyClient] Getting /opt/cmu/image/rhel52_pbs/parttbl-c0d0.raw
[14-Mar-2012_15:36:56] [DollyClient] Getting /opt/cmu/image/rhel52_pbs/partarchi-c0d0p3.tar.bz2 (1/2)
[14-Mar-2012_15:39:18] [DollyClient] Getting /opt/cmu/image/rhel52_pbs/partarchi-c0d0p1.tar.bz2 (2/2)

***
***  backup success
***

golden node reboot in 0s


GRENOBLE NODES:
[root@o184i224 ~]# /opt/cmu/bin/cmu_backup -l pbs_rhel6u2_x86_64 -n o184i225 -p "sda2,sda1"
backup id is 5275
log file is /opt/cmu/log/cmudolly-5275.log
copying ssh settings
hostname setup ok
logout ok
netbooting node
waiting for node o184i225 to boot
<o184i225> netbooted correctly,removing dhcp entry
tail -f /opt/cmu/log/cmudolly-5275.log
Starting retrieving fstab
[29-Oct-2012_19:09:38] [Dolly] Running OS : "Linux-RedHat"
[29-Oct-2012_19:09:38] OSTYPE:Linux-CMU
[29-Oct-2012_19:09:38] [DollyClient] Starting to get fstab
[29-Oct-2012_19:09:38] [DollyClient] Getting "/opt/cmu/image/pbs_rhel6u2_x86_64/fstab-device.txt"
[29-Oct-2012_19:09:44] Dolly Terminated...
starting backup process...
[29-Oct-2012_19:09:44] [Dolly] Add partition "sda2"
[29-Oct-2012_19:09:44] [Dolly] Add partition "sda1"
[29-Oct-2012_19:09:44] [Dolly] Running OS : "Linux-RedHat"
[29-Oct-2012_19:09:44] OSTYPE:Linux-CMU
[29-Oct-2012_19:09:44] [DollyClient]  This is not SLES9 or above. No specific work to do
[29-Oct-2012_19:09:44] [DollyClient]  redhat like OS, launching the script to detect the nic configuration file name used for the cloning
[29-Oct-2012_19:09:45] [DollyClient] Starting to get image
[29-Oct-2012_19:09:45] [DollyClient] Asking for main devices list
[29-Oct-2012_19:09:45] [DollyClient] Device is sda
[29-Oct-2012_19:09:45] [DollyClient] Asking for partition table of "/dev/sda"
[29-Oct-2012_19:09:45] [DollyClient] Getting /opt/cmu/image/pbs_rhel6u2_x86_64/parttbl-sda.txt
[29-Oct-2012_19:09:45] [DollyClient] Getting /opt/cmu/image/pbs_rhel6u2_x86_64/parttbl-sda.raw
[29-Oct-2012_19:09:45] [DollyClient] Getting /opt/cmu/image/pbs_rhel6u2_x86_64/partarchi-sda2.tar.bz2 (1/2)
[29-Oct-2012_19:12:17] [DollyClient] Getting /opt/cmu/image/pbs_rhel6u2_x86_64/partarchi-sda1.tar.bz2 (2/2)
[29-Oct-2012_19:12:19] [DollyClient] Image pbs_rhel6u2_x86_64 received
[29-Oct-2012_19:12:19] Dolly Terminated...

***
***  backup success
***

golden node reboot in 0s


 - After the machine comes back up, verify that packages were installed

Cloning a node.
 - Taking the existing rhel52_pbs logical group and its image, and cloning it to a new node.
 - cmu_add_to_logical_group_candidates -t rhel52_pbs n8
   Need to add the new node to the logical group
 - cmu_clone -n n8 -i rhel52_pbs
   Clones the logical group's image to the new node (n8)

 [root@serisk1 bin]# ./cmu_clone -n n8 -i rhel52_pbs
 making node(s) reservation(s) for cloning ( id: 1583 )
 cleaning /etc/dhcpd.conf
 cleaning boot directory
 configuring the system
 copying ssh settings
 sending power off to selected nodes
 rebuilding network-boot image
 starting cloning # 1583

 cloning started on [14-Mar-2012_15:48:53]

 +-------------------------------------+--+

 cloning process finished on 2012-03-14 at [14-Mar-2012_15:48:53]

 [CerbereDB] Database report:
 [CerbereDB] 	                               | cloned | error | unknown
 [CerbereDB] 	                         Total |      0 |     0 |       0
 [CerbereDB] no node in error
 [CerbereNB] Netboot cleaning (/etc)
 [CerbereNB] Netboot opens /etc/exports
 [CerbereNB] Removing netboot tags in file /etc/exports
 [CerbereServer] Delete "/opt/cmu/ntbt/rp/etc/rc.d/auto/cmucerbere.sh-1583"
  Cerbere is terminating in ERROR with status -1

detailed logs are in /opt/cmu/log/cmucerbere-1583.log and
/opt/cmu/log/cmucerbere-*.log
releasing node(s) reservation(s) for cloning ( id: 1583 )


Useful to obtain metrics from Gen8 systems without loggin into the node (ssh)

[root@o184i224 ~]# /opt/cmu/bin/cmu_get_ams_metrics -h
usage : /opt/cmu/bin/cmu_get_ams_metrics -h
        /opt/cmu/bin/cmu_get_ams_metrics [-d] -a|-f <node_file> [-m mfile] [-s secs]

 -d    : display metric data
 -a    : use all nodes in CMU
 -f <f>: file containing list of nodes
 -m <m>: file containing SNMP OID and corresponding metric name
         default metric file is /opt/cmu/etc/cmu_ams_metrics
 -s <s>: number of seconds to sleep between reruns

[root@o184i224 ~]# cat /opt/cmu/etc/cmu_ams_metrics
#
# This file is part of the CMU AMS support.
# This file maps SNMP OIDs to CMU metric names.
#
# First column is the SNMP OID.
# Second column is the CMU metric name.
# The optional 'SUM' keyword in the third column
# is used to add the values of multiple SNMP OIDs
# into a single CMU metric.
#
SNMPv2-SMI::enterprises.232.6.2.6.8.1.4.0.1  amb1_temp
SNMPv2-SMI::enterprises.232.6.2.6.8.1.4.0.2  cpu1_temp
SNMPv2-SMI::enterprises.232.6.2.6.8.1.4.0.3  cpu2_temp
SNMPv2-SMI::enterprises.232.6.2.9.3.1.7.0.1  power1 SUM power
SNMPv2-SMI::enterprises.232.6.2.9.3.1.7.0.2  power2 SUM power
SNMPv2-SMI::enterprises.232.6.2.9.3.1.7.0.3  power3 SUM power
SNMPv2-SMI::enterprises.232.6.2.9.3.1.7.0.4  power4 SUM power

Customize metrics per application.


Idea - EventLogError, detect errors to potentially update node comments OR react to shutting nodes down and rerunning jobs somewhere.


On computational nodes
./tools/cmu_get_nvidia_gpu
./tools/cmu_get_amd_gpu

